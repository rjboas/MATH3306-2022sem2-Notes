% !TeX TS-program = xelatex
% !TeX options = -aux-directory=Debug -shell-escape -file-line-error -interaction=nonstopmode -halt-on-error -synctex=1 "%DOC%"
\documentclass{article}
\input{LaTeX-Submodule/template.tex}

% Additional packages & macros
\geometry{a4paper}
\DeclareMathOperator{\blank}{\text{\textvisiblespace}}
\setmathfont[range=\setminus]{Asana Math} % Fix setminus not showing

\usepackage{tikz}
\usetikzlibrary{automata} % Import library for drawing automata
\usetikzlibrary{positioning} % ...positioning nodes
\usetikzlibrary{arrows.meta} % ...customizing arrows
\tikzset{
    node distance=2.0cm, % Minimum distance between two nodes. Change if necessary.
    every state/.style={ % Sets the properties for each state
        semithick,
        fill=gray!10
    },
    initial text={}, % No label on start arrow
    double distance=2pt, % Adjust appearance of accept states
    every edge/.style={ % Sets the properties for each transition
        draw,
        ->,
        % >=stealth’, % Makes edges directed with bold arrowheads
        auto,
        semithick
    }
}

% Header and footer
% ! Unit name
\newcommand{\unitName}{Set Theory \& Mathematical Logic}
% ! Unit code
\newcommand{\unitCode}{MATH3306}
% ! Unit semester 
\newcommand{\unitTime}{Semester 2, 2022}
% ! Unit coordinator name
\newcommand{\unitCoordinator}{Professor Benjamin Burton}
% ! Document authors
\newcommand{\documentAuthors}{Rohan Boas}

\fancyhead[L]{\unitName}
\fancyhead[R]{\leftmark}
\fancyfoot[C]{\thepage}

% Copyright
\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
    imagewidth={5em},
    hyphenation={raggedright}
]{doclicense}

\date{}

\begin{document}

\begin{titlepage}
    \vspace*{\fill}
    \begin{center}
        \Large{\unitCode} \\[0.05in]
        \LARGE{\textbf{\unitName}} \\[0.1in]
        \normalsize{\unitTime} \\[0.2in]
        \normalsize\textit{\unitCoordinator} \\[0.2in]
        \documentAuthors
    \end{center}
    \vspace*{\fill}
    \doclicenseThis
    \thispagestyle{empty}
\end{titlepage}
\newpage

\tableofcontents
\newpage

\section{Introductory notes}
\subsection{Gödel's incompleteness theorem}
\begin{theorem}[Gödel's incompleteness theorem, informal version]
    There are true mathematical statements that cannot be proven.
\end{theorem}
\begin{proof}[``Proof'']
    Take the statement ``This statement has no proof.''

    \emph{Assume it is false.}
    This implies that the statement has a proof.
    If the statement has a proof, it must be true, contradiction!

    \emph{Assume it is true.}
    This implies that the statement has no proof.
    Therefore, the statement cannot be proven.
\end{proof}
\subsection{The halting problem}
We would like to be able to know if an algorithm or program
will halt or will loop forever.
Can we write an algorithm which can tell us whether or not
a given program will halt on a given input?
This is known as the halting problem.
The halting problem is undecidable.
\begin{proof}[Proof by contradiction]
    Say there does exist some program H which solves the halting problem.
    Let us define H.
    H takes as inputs a program, \(x\),
    and an input for that program, \(y\).

    \[
        \text{H}(x,y) =
        \begin{cases}
            \text{YES}, \quad & \text{if } x \text{ halts on input } y         \\
            \text{NO},        & \text{if } x \text{ loops forever on input } y
        \end{cases}
    \]

    Let us define a program Foo.
    \[
        \text{Foo}(x) =
        \begin{cases}
            \text{loops forever}, \quad & \text{if } \text{H}(x,x) \text{ is YES} \\
            \text{halts}, \quad         & \text{if } \text{H}(x,x) \text{ is NO}  \\
        \end{cases}
    \]

    TODO: finish proof, maybe rewrite with diagram
\end{proof}

\subsection{Defining algorithms}
In defining algorithms, Turing machines
and recursive functions will be the primary focus.
Grammars and code are also alternatives.
\begin{definition}[Church-Turing thesis, informal version]
    Any reasonable definitions of ``algorithm'' are equivalent.
\end{definition}
\newpage
\section{Finite and deterministic state automata}
\subsection{Finite state automata}
\begin{definition}[Alphabet]
    An alphabet \(A\) is a finite set of symbols.
\end{definition}
\begin{definition}[Word]
    A word is a sequence of symbols from \(A\).
\end{definition}
\begin{theorem}
    Words can be concatenated.
    E.g. \ for words \(\alpha\) representing ``bob'',
    and \(\beta\) representing ``cat'',
    \(\alpha\beta\alpha\) represents ``bobcatbob''.
\end{theorem}
\begin{theorem}
    The set of words length \(m\) is \(A^m = A\times A\times \cdots \times A\).
\end{theorem}
\begin{theorem}
    The empty word (i.e.\ of length 0) is \(\varepsilon\).
\end{theorem}
\begin{theorem}
    \(A^*\) is the set of all words over \(A\). \(A^* = \bigcup_{m\ge 0} A^m\).
\end{theorem}
\begin{theorem}
    \(A^+\) is the set of all non-empty words over \(A\). \(A^+ = \bigcup_{m\ge 1} A^m\).
\end{theorem}
\begin{definition}[Language]
    A language is a subset of \(A^*\)
\end{definition}
\begin{definition}[Finite state automata]
    A finite state automaton (FSA)
    can be defined as the 5-tuple
    \(\left(Q, F, A, \tau, q_o\right)\) where
    \begin{itemize}
        \item    \(Q\) is a finite set of states,
        \item    \(F\subseteq Q\) is the set of final/accepting states,
        \item    \(A\) is a finite alphabet,
        \item    \(\tau\subseteq Q\times A\times Q\) is the set of transitions, and
        \item    \(q_0\) is the initial state.
    \end{itemize}
\end{definition}
\begin{definition}[Computation]
    A computation is a sequence \(q_0 a_1 q_1 a_2 \ldots a_n q_n\)
    such that each \(q_i a_{i+1} q_{i+1} \in \tau\).
\end{definition}
\begin{definition}[Successful]
    A computation is successful if \(q_n \in F\).
\end{definition}
\begin{definition}[Accepted]
    A word \(\alpha = a_1 a_2 \ldots a_n\)
    is accepted by the FSA if there is a
    successful computation \(q_0 a_1 q_1 a_2 \ldots a_n q_n\).
\end{definition}
\begin{definition}[Recognised]
    The language recognised by an FSA is
    the set of all words it accepts. 
\end{definition}
\begin{note}
    A FSA is like a backtracking search.
\end{note}
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
    \node[state] (A) {$-$};
    \node[state, above right of=A] (B) {};
    \node[state, below right of=B] (R) {$R$};
    \node[state, right of=B] (Z) {+};
    \draw (A) edge node {$a$} (B);
    \draw (A) edge node {$b$} (R);
    \draw (B) edge node {$a$} (R);
    \draw (B) edge node {$b$} (Z);
    \draw (R) edge[loop below] node {$a$} (R);
    \draw (R) edge[loop right] node {$b$} (R);
    \draw (Z) edge[loop above] node {$a$} (Z);
    \draw (Z) edge[loop right] node {$b$} (Z);
    \end{tikzpicture}
    \caption{
        A simple FSA (that is also a DFA)
    }
    \(-\) denotes the initial state, \(+\) is an accepting state,
    and \(R\) is a rejection state/``black hole''.
\end{figure}
\subsection{Deterministic finite state automata}
\begin{definition}[Deterministic finite state automata]
    A deterministic state automaton (DFA) is an FSA where
    \(
        \forall q \in Q, \forall a \in A,
        \exists! q' \in Q \st \left(q,a,q'\right)\in\tau
    \)
\end{definition}
\begin{theorem}
    The definition of DFA implies there exists a function \(\delta: Q \times A \to A\).
\end{theorem}
\begin{theorem}
    FSA and DFA solve the same problems.
    
    A DFA is already an FSA,
    and an FSA can be represented by a DFA of the reachable sets of states.
    Though, for an FSA with \(n\) states,
    the corresponding DFA has up to \(2^n\) states.
\end{theorem}
\begin{theorem}
    FSA/DFA can perform addition.
\end{theorem}
\begin{theorem}
    FSA/DFA \emph{cannot} perform multiplication.
\end{theorem}
\begin{theorem}
    To recognise an infinite language of a DFA with a finite complement,
    find the complement and swap accepting and rejecting states.
\end{theorem}

\newpage
\section{Turing machines}
\begin{definition}[Turing machine]
    A Turing machine (TM) is a FSA with infinite memory
    in the form of a tape.
    
    A Turing machine is a tuple \(\left(Q, F, \blank, A, I, \tau, q_0\right)\) where
    \begin{itemize}
        \item    \(Q\) is a finite set of states,
        \item    \(F\subseteq Q\) is the set of final/accepting states,
        \item    \(\blank\) is the ``blank'' symbol
        which is present on the tape where no new symbol has been written,
        \item    \(A\) is a finite alphabet of all symbols
        that may be on the tape (including \(\blank\)),
        \item    \(I\subseteq A - \left\{\blank\right\}\) is a finite alphabet of all
        symbols from the input sequence,
        \item    \(\tau\subseteq Q\times A\times Q\times A\times \left\{L, R\right\}\)
        is the set of transitions, and
        \item    \(q_0\) is the initial state.
    \end{itemize}
\end{definition}
\begin{definition}[Tape]
    A tape is a tuple \(\left(a, \alpha, \beta\right)\) where
    \begin{itemize}
        \item \(a\in A\),
        \item \(\alpha, \beta : \N\to A\), and
        \item \(\alpha(i), \beta(i) \ne \blank\) for only finitely many \(i\).
    \end{itemize}
\end{definition}
\begin{definition}[Configuration]
    A configuration is a snapshot of the state.

    A configuration is a tuple \(\left(q\in Q, a, \alpha, \beta\right)\).
\end{definition}
\begin{definition}[Reachable]
    A configuration \(c'\) is reachable from \(c\) in a single move if
    for \(c = \left(q, a, \alpha, \beta\right)\),
    (in the case of moving to the right)
    \(c' = \left(q', a(0), \alpha', \beta'\right)\) where
    \begin{itemize}
        \item \(\alpha'(i)=\alpha(i+1) \quad \forall i \in \N\),
        \item \(\beta'(i)=\begin{cases}
            \beta(i-1) & \forall i \ge 1 \\
            a' & i=0
        \end{cases}\), and
        \item \(\left(q, a, q', a', R\right)\in\tau\).
    \end{itemize}
\end{definition}
\begin{definition}[Computation]
    A computation is a finite sequence of configurations
    \(c_0 c_1 c_2 \ldots c_n\) \st
    \(c_i\) is reachable from \(c_{i-1}\) is a single move for all \(i\).
\end{definition}
\begin{definition}[Terminal]
    A configuration is terminal if no configuration is reachable from it.
    A Turing machine halts upon reaching such a configuration.
\end{definition}
\begin{definition}[Acceptinng]
    A Turing machine accepts a word \(w\in I^*\)
    if there exists some computation from the initial state \(c_w\)
    to some final state.
\end{definition}
\begin{definition}[Recognised]
    The language recognised by a Turing machine
    is the set of all words \(w \in I^*\) that the Turing machine accepts.
\end{definition}
\begin{definition}[Deterministic]
    A Turing machine is deterministic if   
    for all \(q\) and \(a\), there exists at most one tuple
    \(\left(q, a, q', a', d\right)\in\tau\).
\end{definition}
\begin{theorem}
    The transitions of a Turing machine are partial functions
    of the form
    \(\delta : Q\times A \to Q \times A \times \left\{L, R\right\}\)
\end{theorem}
% TODO: Aside on P vs NP?
\newpage
\section{Recursive functions}
\subsection{Base definitions}
\begin{definition}[Total function]
    A total function is an ordinary function, i.e.
    \(f: D\to C \st f\subseteq D\times C \text{ where }
    \forall d \in D \,\exists! c\in C \st \left( d, c \right)\in f\).
\end{definition}
\begin{definition}[Partial function]
    A partial function is \(f: D\to C \st f\subseteq D\times C \text{ where }
    \forall d \in D \,\exists_{\leq 1} c\in C \st \left( d, c \right)\in f\).
    I.e.\ undefined values are permitted.
\end{definition}
\begin{note}
    By convention, if not specified a function is \(f:\N^r\to\N\).
\end{note}

\subsection{Initial functions}
\begin{itemize}
    \item Zero: \(z:\N\to\N,\; z(n) = 0 \;\forall n\)
    \item Successor: \(\sigma:\N\to\N,\; \sigma(n) = n + 1 \;\forall n\)
    \item Projection: \(\pi_{i,n}:\N^n\to\N,\; \pi_{i,n}(k_1,\ldots,k_n) = k_i\)
\end{itemize}
\begin{definition}[Composition]
    Given \(g:\N^r\to\N\), and
    \(h_1,\ldots,h_r:\N^n\to\N\),
    \(f:\N^n\to\N\) is defined by
    \begin{align*}
        f(x_1,\ldots,x_n) 
        = g(& \\
        &\quad h_1(x_1,\ldots,x_n), \\
        &\qquad \vdots \\
        &\quad h_r(x_1,\ldots,x_n) \\
        )
    \end{align*}
\end{definition}
\subsection{Primitive recursion}
\begin{definition}[Primitive recursion]
    A primitive recursion on
    \(g:\N^n\to\N\) and
    \(h:\N^{n+2}\to\N\)
    is defined as \(f:\N^{n+1}\to\N\) \st
    \begin{align*}
        f\left(x_1,\ldots,x_n,0\right) = g(&x_1,\ldots,x_n) \\
        f\left(x_1,\ldots,x_n,y+1\right) = h(&
            \\
            &\quad x_1,\ldots,x_n, \\
            &\quad y, \\
            &\quad f\left(x_1,\ldots,x_n,y+1\right) \\
        &)
    \end{align*}
\end{definition}
\begin{note}
    Primitive recursion can only go from \(y\) to \(y+1\)
    and can only recurse over a signle variable.
\end{note}
\begin{note}
    We can only return a single integer, however,
    we can store pairs etc.\ by combining them in a retrievable way,
    for example, \(2^x \times 3^y\) could be chosen to store \(\left( x,y \right)\).
\end{note}
\begin{theorem}
    Primitive recursive functions are the smallest class of functions
    that contain the initial functions and
    is closed under composition and primitive recusrsion.
\end{theorem}
\begin{theorem}
    Addition can be represented as a primitive recusrion, \(s(x, y) = x+y\),
    with
    \begin{align*}
        s(x,0) &= \pi_{1,1}(x) \\
        s(x,y+1) &= \sigma(s(x,y))
    \end{align*}
\end{theorem}
\begin{theorem}
    Multiplication can be represented as a primitive recusrion, \(m(x, y) = x\times y\),
    with
    \begin{align*}
        m(x,0) &= z(x) \\
        m(x,y+1) &= s(x, m(x,y))
    \end{align*}
\end{theorem}
\begin{definition}[Primitive recusrive definition of a function]
    The primitive recusrive definition of a function
    \(f:\N^n\to\N\) is a finite set of functions \(\left\{f_0,\ldots,f_k\right\}\) \st
    \begin{align*}
        \forall i,\, f_i &= \begin{cases}
            \text{initial function} \\
            \text{composition of functions from } \left\{ f_j \,|\, j < i \right\} \\
            \text{primitive recursion of functions from } \left\{ f_j \,|\, j < i \right\}
        \end{cases} 
    \end{align*}
\end{definition}
\begin{theorem}
    A primitive recursion is equivalent to a primitive recusrive definition.
\end{theorem}
\begin{theorem}
    The constant function is \(c_i:\N\to\N\) where
    \(c_i(x)=i\).
    
    \[
        c_i=\overbrace{
            \sigma\left( \sigma\left(  \ldots \sigma\left( z \right) \right) \right)
        }^{i \text{ times}}
    \]
\end{theorem}
\begin{theorem}
    The sign function \(Sg:\N\to\N\) is
    \begin{equation*}
        Sg(x) = \begin{cases}
            0, & x = 0 \\
            1, & x > 0
        \end{cases}
    \end{equation*}
\end{theorem}
\begin{theorem}
    The predecessor function \(Pred:\N\to\N\) is
    \begin{equation*}
        Pred(x) = \begin{cases}
            0  , & x = 0 \\
            x-1, & x > 0
        \end{cases}
    \end{equation*}
\end{theorem}
\begin{theorem}
    The subtraction function \(\dotminus:\N^2\to\N\) is
    \begin{equation*}
        x\dotminus y = \begin{cases}
            0  , & x < y \\
            x-y, & x \ge y
        \end{cases}
    \end{equation*}
\end{theorem}
\begin{theorem}
    The absolute value function \(\left|x-y\right|:\N^2\to\N\) is
    \begin{equation*}
        \left|x-y\right| = \begin{cases}
            y-x  , & x < y \\
            x-y, & x \ge y
        \end{cases}
    \end{equation*}
    \[
        \left|x-y\right| = \left( x \dotminus y \right) + \left( y \dotminus x \right)
        = s\left( x \dotminus y, y \dotminus x \right)
    \]
\end{theorem}
\begin{theorem}
    The exponentiation function \(x^y:\N^2\to\N\) is
    \begin{align*}
            x^0 &= 1 \\
            x^{y+1} &= m(x^y, x)
    \end{align*}
    
    N.B. tetration is also primitive recursive.
\end{theorem}
\begin{theorem}
    For every function \(f:\N\to\N\) there is a summation function \(\sum_{i=0}^x f(i)\).
\end{theorem}
\begin{theorem}
    If \(f\) is primitive recursive then \(\sum_{i=0}^x f(i)\) is
    also primitive recusrive.
\end{theorem}
\begin{theorem}
    For every function \(f:\N\to\N\) there is a
    bounded minimisation function \(\min_{i\le y} f(i)\).
    This function gives the smallest \(f(i) \ne 0\),
    and gives \(y+1\) if all \(f(i) = 0\).
\end{theorem}
\begin{note}
    The following are not primitive recursive:
    \begin{enumerate}
        \item Unbounded/infinite summantion
        \item Unbounded minimum
    \end{enumerate}
\end{note}
\begin{theorem}
    The Ackerman function is \(f:\N^2\to\N\) where
    \[
        f(x,y) = \begin{cases}
            y+1, & x=0 \\
            f(x-1, 1), & y=0<x \\
            f(x-1, f(x, y-1)), & \text{otherwise}
        \end{cases}
    \]
    
    \begin{figure}[H]
        \begin{center}
        \begin{tabular}{c|c|c|c|c|c|c|c}
         & x=0 & 1 & 2 & 3 & 4 & 5 & \(\cdots\) \\
        \midrule
        y=0 & 1 & 2 & 3 & 4 & 5 & 6  & \(\cdots\)\\ \midrule
        1 & 2 & 3 & 4 & 5 & 6 & 7  & \(\cdots\)\\ \midrule
        2 & 3 & 5 & 7 & 9 & 11 & 13  & \(\cdots\)\\ \midrule
        3 & 5 & 13 & 29 & 61 & 125 & 253  & \(\cdots\)\\ \midrule
        4 & 13 & 65533 & \text{huge} & \(\cdots\) & \(\cdots\) & \(\cdots\)  & \(\cdots\)\\ \midrule
        \end{tabular}            
        \end{center}
        \caption{A table of some values of the Ackerman function}
    \end{figure}
\end{theorem}
\begin{theorem}
    The Ackerman function is \emph{not} primitive recursive.
   
    % \begin{proof}

    % Notation: \(A_m(n):\N\to\N\) is the \(n\)th row of the Ackerman function
    % which is \(A(m,n)\),
    % i.e. \(A_0(n)=n+1\), \(A_1(n)=n+2\), etc.
    
    % Facts for all \(m, n\)
    % \begin{itemize}
    %     \item \(n<A_m(n)\)
    %     \item \(A_m(n)<A_m(n+1)\)
    %     \item \(A_m(n)<A_{m+1}(n)\)
    % \end{itemize}
    % Proofs left as an excersise to the reader.
    
    % Notation: \(f^{(k)}(x) = \overbrace{f(f(\cdots f(x))\cdots)}^{k \text{ times}}\)
    % \begin{lemma}
    %     \[n \le A_0^{(n-1)}(1) \forall m, \forall n \ge 1\]
    %     \begin{proof}

    %         For \(m=0\),
    %         \(n \le A_0^{(n-1)}(1) = 1 + \overbrace{1+1+\cdots+1}^{n-1 \text{ times}} = n\).

    %         For \(m>0\),
    %         \begin{align*}
    %             A_m^{(n-1)}(1) &= \overbrace{A_m(A_m(\cdots A_m(1))\cdots)}^{n-1 \text{ times}} \\
    %             &\ge \overbrace{A_{m-1}(A_m(\cdots A_m(1))\cdots)}^{n-1 \text{ times}} \\
    %             &\ge \overbrace{A_{m-1}(A_{m-1}(\cdots A_m(1))\cdots)}^{n-1 \text{ times}} \\
    %             &\ge A_{m-1}^{(n-1)}(1) \ge n
    %         \end{align*}
    %     \end{proof}
    % \end{lemma}
    % \begin{lemma}
    %     \[A_m^{(n+1)}(1)=A_{m+1}(n)\]
    %     \begin{proof}
            
    %         For \(m=0\),
    %         \begin{align*}
    %              A_m^{(n+1)}(1) &= \overbrace{1+1+\cdots+1}^{n+1 \text{ times}} = n + 2 \\
    %              &= A_1(n) = n+2 \\
    %         \end{align*}
            
    %         For \(m>0\), induct on \(n\).
    %         Base case: \(A_m^{(1)}(1)=A_{m+1}(0)\), true by formula.
    %         Inductive step:
    %         Let \(n>0\),
    %         \begin{align*}
    %             A_m^{(n+1)}(1) &= A_{m+1}(n) \\
    %                            &= A_m(A_{m+1}(n-1)) \\
    %                            &= A_m(A_{m}^{(n)}(1)) \\
    %                            &= A_{m}^{(n+1)}
    %         \end{align*}
    %     \end{proof}
    % \end{lemma}
    
    % Finish proof:

    % Claim: \(\forall\) primitive recursive functions \(p:\N^n\to\N\),
    % \(\exists i \st p<A_i\).
    % I.e. it can be bound by a row of the Ackerman function.
    
    % \begin{proof}
    %     Induct on length of the primitive recusrive definition.
        
    %     Initial functions:
    %     \begin{align*}
    %         z(n) &< A_0(n) \\
    %         \sigma(n) &< A_1(n) \\
    %         \pi_{i,n}(x_1,\ldots,x_n) &< \max x_1,\ldots,x_n < A_0(\max x_1,\ldots,x_n)
    %     \end{align*}
        
    %     Composition:
    %     Suppose \(g,h:\N\to\N\).
    %     \(g\) is prim. rec., \(g < A_i\)
    %     and
    %     \(h\) is prim. rec.,\(h < A_j\).

    %     Find some row \(q\) \st \(g(h(n))<A_q(n)\).
        
    %     Claim:
    %     \(g(h(n))<A_{m+2}(n)\) where \(m=\max (i,j)\).
    %     Since 
    %     \begin{align*}
    %         g(h(n)) &< A_i(A_j(n)) \\
    %         &\le A_m(A_{m+1}(n)) \\
    %         &\le A_m(A_m^{(n+1)}(n)) \\
    %         &\le A_m^{(n+2)}(n) \\
    %         &\le A_{m+1}(n+1) \\
    %         &\le A_{m+2}(n) \quad \text{(proof of this lemma elided)}
    %     \end{align*}
        
    %     Primitive recusrion:
    %     Let \(g:\N^n\to\N\), \(h:\N^{n+2}\to\N\).
    %     \begin{align*}
    %         f(x,\ldots,x_n,0) &= g(x,\ldots,x_n) \\
    %         f(x,\ldots,x_n,y+1) &= h(x,\ldots,x_n,y,f(x,\ldots,x_n,y))
    %     \end{align*}
    %     Assume
    %     \begin{align*}
    %         g(x,\ldots,x_n) &< A_r(\max x_i) \\
    %         h(x,\ldots,x_n,y,f(x,\ldots,x_n,y,z)) &< A_s(\max x_i,y,z)
    %     \end{align*}
    %     Claim: \(f(x,\ldots,x_n,0) < A_q(y+\max x_i)\) where \(q=\max(r,s)+1\).

    %     Proof elided.
    % \end{proof}
        
    %     Let \(z = \max x_i, y\).
        
    %     Claim: \(f(x,\ldots,x_n,y) \le A_{q+1}(\max x_i,y)\).
        
    %     Proof elided.
    % \end{proof}
    
    I tried transcribing the proof but it turned into a bit of a mess,
    see lecture 2 of week 3 recording for the full thing or the source code
    where I've left my attempt commented out.
\end{theorem}
\begin{remark}
    Primitive recusrion is not the ``right'' definition of ``computable''.
\end{remark}

\begin{theorem}
    Predicates are 
\end{theorem}
\begin{definition}
    The characteristic function of a predicate \(P\)
    is 
    \[\chi_P(x_1,\ldots,x_n) = \begin{cases}
        1 & P(x_1,\ldots,x_n) \\
        0 & \lnot P(x_1,\ldots,x_n) \\
    \end{cases}\]
\end{definition}
\begin{theorem}
    A predicate is primitive recursive when \(\chi_P\)
    is primtive recursive.
\end{theorem}
\begin{theorem}
    The following functions and predicates
    are primtive recursive.
    \begin{itemize}
        \item \(\ne\) (\(Sg(x\dotminus y)+Sg(y\dotminus x)\))
        \item \(=\) (\(1\dotminus \chi_\ne(x,y) \))
        \item \(\lnot P\)
        \item \(p \land q\) (\(\chi_p \cdot\chi_q\))
        \item \(p \lor q\) (use De Morgan's law)
    \end{itemize}
\end{theorem}
\begin{theorem}
    Bounded exists (\(\exists y\le z\)) and
    bounded forall (\(\forall y\le z\))  are primtive recursive.
\end{theorem}
\begin{theorem}
    \(x|y\) is primitive recusrive.
    \[
    \chi_{x|y}=\exists_{k\le y} (y=k\cdot x)  
    \]
\end{theorem}
\begin{theorem}
    Prime tests and a function for the \(n\)th prime
    are primtiive recursive.
\end{theorem}
\begin{definition}[Iteration]
    For a function \(f:X\to X\),
    the \(i\)th iterate of \(f\)
    is \(F:X\times \N \to X\) where
    \begin{align*}
        F(x, i) &= \overbrace{f(f(\ldots(f(x))\ldots))}^{i \text{ copies of } f} \\
        F(x, 0) &= x
    \end{align*}
\end{definition}
\begin{theorem}
    If \(f\) is primitive recursive,
    \(F\) is also primitive recursive.
\end{theorem}
\begin{theorem}
    Iteration is equivalent to primitive recursion,
    i.e. the class of primitive recursive functions
    is the smallest class of functions containing
    the intial functions and is closed under
    composition and iteration. 
\end{theorem}
\begin{definition}[Hyperoperation]
    \begin{align*}
        a[1]b &= a + b \\
        a[2]b &= ab \\
        a[3]b &= a^b \\
        a[k]b &= \underbrace{ a[k-1]( a[k-1] ( \ldots a[k-1]a \ldots ) ) }_{b \text{ times}}
    \end{align*}
\end{definition}
\begin{theorem}
    If \(f\) is primitive recursive,
    the running time to compute \(f\) (on a TM)
    is at most \(2[k]n\) for some fixed \(k\in\N\).
\end{theorem}
\begin{definition}[Minimisation]
    Minimisation (unbounded)
    is a partial function \(\mu y\).
    \begin{align*}
        \mu y f(\underline{x}, y) = \begin{cases}
            r & f(\underline{x}, r) =
            0
            \text{ or } f(\underline{x}, s) \ne 0
            \text{ and is defined } \forall s < r \\
            \text{undefined}
        \end{cases}
    \end{align*}
\end{definition}
\begin{definition}[Regular minimisation]
    Regular minimisation is \(\mu y\) where
    \(\mu y f(\underline{x}, y) = 0\) is defined for all \(\underline{x}\).
\end{definition}
\begin{definition}[Partial recursive functions]
The smallest class that contains the initial functions
and is closed under composition, primitive recusrion and minimisation.
\end{definition}
\begin{definition}[Recursive functions]
The smallest class that contains the initial functions
and is closed under composition, primitive recusrion and regular minimisation.
\end{definition}
\begin{definition}[Numerical Turing machines]
    A numerical Turing machine is a
    deterministic Turing machine
    with no final states
    and the alphabest is \(\left\{ 0, 1 \right\}\)
    where \(0\) is the blank symbol.
\end{definition}
\begin{theorem}
    To compute \(f(x_1, \ldots, x_n)\) on a numerical TM,
    start with an initial tape with \(x_1\) 1s, a 0, \(x_2\) 1s, a 0, and so on,
    with the head at the 0 before \(x_1\).
    Let it run.
    If it halts in a configuration like \(00\ldots \overline{0}11\ldots 100\ldots \)
    then the output is the number of 1s, else undefined.
\end{theorem}
\begin{theorem}
    \(\forall\) numerical TMs \(T\),
    \(\forall n \ge 1\), \(T\) defines a partial function
    \(\varphi_{T,n}:\N^n\to\N\).
\end{theorem}
\begin{theorem}
    \(f:\N^n\to\N\) is TM-computable if
    there is some TM which computes \(f\).
\end{theorem}
\begin{theorem}
    \(f\) is partial recusrive iff \(f\) is TM-computable.
\end{theorem}
\begin{definition}[Decidable]
    Some predicate \(P\) is decidable if \(\chi_P\)
    is recursive.
\end{definition}
\begin{definition}[Halting problem]
    \[
        g:\N^2\to\N=\begin{cases}
        1 & \text{ if \(x\) represents a TM and \(\varphi_{T_x, 1}(i)\) is defined} \\
        0
        \end{cases}
    \]
    \begin{theorem}
        \(g\) is not partial recursive.
        
        \begin{proof}
            Let \(f:\N\to\N\)
            \[
                f(x) = \begin{cases}
                    1 & g(x, x) = 0 \\
                    \text{undefined} & g(x, x) = 1
                \end{cases}
            \]
            
            Claim: if \(g\) is partial recursive, then so is \(f\).
            Therefore, \(f\) is TM-computable.
            Therefore, \(f = \varphi_{T_n,1}\) for some \(n\).

            What is \(f(n)\)?

            \(g(n,n)=0 \implies f(n) = 1 \implies g(n, n) = 1\), contradiction.

            \(g(n,n)=1 \implies f(n) \text{ undefined } \implies g(n, n) = 0\), contradiction.

            Therefore, our assumption was wrong and so \(g\) is not partial recursive.
        \end{proof}
    \end{theorem}


    TODO move stuff around.
    
    How to encode TM in \(\N\)?
    Gödel numbering:

    Alphabet symbols are \(s_0, s_1, \ldots\) where \(s_0\) is blank.
    States are \(q_0, q_1, \ldots\) where \(q_0\) is initial.
    Transition function \(\subseteq Q\times A \times Q \times A \times \left\{ L, R \right\}\).

    Assign numbers to everything: \(x: L R s_0 q_0 s_1 q_1 \ldots\)
    \(\ceil{x}: 2 3 4 5 6 7 \ldots\)

    Arrows \(\tau \in \) transition functions, \(t = \left( a, b, c, d, e \right)\)
    \(\ceil{t} = 2^{\ceil{a}} 3^{\ceil{b}} 5^{\ceil{c}} \cdots\)

    Only thing we need is the arrows.
    
    TM by transition functions \(\left\{ t_0, t_1, \ldots \right\}\)
    is 
    \(\ceil{t} = 2^{\ceil{t_0}} 3^{\ceil{t_1}} 5^{\ceil{t_2}} \cdots\)
    
    So we can feed a TM as an input where we need an \(\N\).
    
    If \(x = \ceil{TM}\), the TM is \(T_x\).
\end{definition}
\begin{theorem}
    The number of TMs is countable.
\end{theorem}
\begin{theorem}
    \(\varphi:\N^2\to\N\)
    \[
        \varphi(x, y) = \begin{cases}
            \varphi_{T_x, 1}(y) & x \text{ represents a TM} \\
            \text{undefined}
        \end{cases}
    \]
    
    \(\varphi\) simulates a TM.
    \(\varphi\) is partial recursive.
    Therefore, \(\varphi\) is TM-computable. ``A universial TM''
\end{theorem}
\newpage
\section{Formal systems}
\begin{definition}[Formal system]
    A formal system is a set of grammars with a set of axioms and inferences.
\end{definition}
\begin{definition}[Robinson's theory Q]

\end{definition}
\begin{definition}[Peano arithmetic]

\end{definition}
\begin{definition}[Consistency]
    \(T\) is consistent if \(\nexists\) statement \(Q\)
    \st \(T\vdash Q\) and \(T\vdash\lnot Q\).
\end{definition}
\begin{definition}[\(\omega\)-consistency]
    \(T\) is \(\omega\)-consistent if \(\nexists\) formula
    \(\varphi(x)\) \st
    \begin{itemize}
        \item \(T \vdash \varphi(\bar{n})\) for every numeral \(\bar{n}\), and
        \item \(T \vdash \lnot \forall x\, \varphi(x)\).
    \end{itemize}
    I.e.\ you cannot prove every individual case of a formula and also
    prove there exists a counterexample.
\end{definition}
\begin{definition}[Numeral]
    A numeral is a logical symbol \(SS\cdots S 0\)
    for some number of `S's.
    Define \(\bar{n}\) to be the numeral with \(n\) `S's.
\end{definition}
\begin{definition}[Recusrively enumerable]
    A set \(A \subseteq \N\) is recusively enumerable if
    \(A\) is a range of some recursive function \(f:\N\to\N\)
    or \(A = \emptyset\).
    
    I.e.\ there is a turing machine which computes the members of the set \(A\)
    after a finite number of steps.
\end{definition}
\begin{definition}[Theorem]
    A theorem \(Q\) in \(T\) is a statement in \(T \st T \vdash Q\).
\end{definition}
\begin{definition}[Efficiently axiomatised]
    A formal system \(T\) is efficiently axiomatised if
    the set of all theorems in \(T\) is recusrively enumerable.
\end{definition}
Is formal arithmetic eifficently axiomatised?
\begin{itemize}
    \item Robinson's theory Q
        \rightarrow Yes, test \(0, 1, \ldots\) as the Gödel number of a proof
        (easy since finitely many axioms).
    \item Peano arithmetic
        \rightarrow Yes, the set of induction axioms
        is recusively enumerable so we can still check.
\end{itemize} 
\begin{definition}[Representability]
    Let \(R\) be a \(k\)-ary relation (i.e. \(R\subseteq\N^k\)).
    \(R\) is represented by the formula
    \(\varphi(v_1,\ldots,v_k)\) if
    \begin{itemize}
        \item  \(T \vdash \varphi(\bar{n_1},\ldots,\bar{n_k})\) when \(R(n_1,\ldots,n_k)\) is true
        \item  \(T \vdash \lnot\varphi(\bar{n_1},\ldots,\bar{n_k})\) when \(R(n_1,\ldots,n_k)\) is false
    \end{itemize}
\end{definition}
\begin{theorem}
    If \(R\) is recusrive, \(R\) is represented in the FA \(T\).
    
    Examples: \(x|y\), \(p\) is prime,
    \(m\) is the GN of a formula with one free variable,
    \(m,n\) where \(m\) is the GN of a proof of the sentence \(n\).
\end{theorem}
\begin{theorem}[Gödel's first incompleteness theorem]
    Let \(T\) be a formal system that
    \begin{itemize}
        \item is efficiently axiomatised,
        \item is \(\omega\)-consistent, and
        \item contains Robinson's theory Q.
    \end{itemize}
    
    Then \(T\) is incomplete,
    i.e. there are true statements without a proof (nor proof of the negation).
    
    \begin{proof}[Proof \#1 (via Halting problem)]
        Assume \(T\) is complete.
        Aim to solve the halting problem: define
        \[Halt(m,x)=\begin{cases}
            1 & \text{if \(TM_{m,1}\) halts on input } x \\
            0 & \text{otherwise}
        \end{cases}\]
        Simelataneously,
        \begin{itemize}
            \item simulate \(TM_{m,1}\) on input \(x\) with a universal TM, and
            \item enumarate all theorems in \(T\)
            until we see ``\(TM_{M,1}(x)\) does not halt.''
            i.e. (and let \(\varphi\) be) \(\forall s\), \(s\) is not a sequence of steps for
            \(TM_{m}\) that starts with input \(x\) and ends in a halting state.
        \end{itemize}
        If the first halts, output 1.
        If the latter produces a theorem, output 0.
        This algorithm must fail for some \(m,x\), else we can solve the halting problem.
        Therefore, \(m\) does not halt on \(x\), and \(\varphi\) is not a theorem of \(T\).
        This means \(T \nvdash \varphi\).
        If \(T\vdash \lnot \varphi\), \(T\vdash \exists s \st s\) is a sequence which does halt.
        But, give me a sequence \(s\), I can simulate \(TM_{m}\) on \(x\)
        and write out its behaviour, which shows \(T \vdash s\) is not a halting sequence.
        By \(\omega\)-consistency, \(T\nvdash \lnot \varphi\).
        
        Therefore, \(T\) is incomplete.
    \end{proof}
    
    Fact: we can use consistency rather than \(\omega\)-consistency to prove this.
    
    \begin{proof}[Proof \#2 (via undecidable statement)]
        Using FA as our formal system.
        Define \(Pf(x,y,z)\subseteq\N^3\) to be
        \(y\) is the GN of a formula \(\varphi\) with one free variable
        and \(x\) as a proof of \(\varphi(\bar{z})\). 
        Recusive \(\therefore\) is represented by formula \(\underline{Pf}(x,y,z)\).
        Build new formula \(\psi(y):\nexists x Pf(x,y,y)\),
        (i.e. FA cannot prove \(\psi_y(\bar{y})\)).
        Let \(g\) be the GN of \(\psi\).
        \(\psi(g)\) enocdes ``FA cannot prove \(\psi(g)\)''.
        
        \begin{itemize}
            \item If FA \(\vdash \psi(\bar{g})\),
        Let \(m\) be the GN of the proof.
        Therefore, \(Pf(m,g,g)\) is true.
        Therefore, FA \(\vdash \underline{Pf}(\bar{m}, \bar{g}, \bar{g})\).
        Therefore, FA \(\vdash \exists x\underline{Pf}(x, \bar{g}, \bar{g})\).
        Therefore, FA \(\vdash \lnot\psi(\bar{g})\).
        Therefore, FA is inconsistent.
        Contradiction (elided: show \(\omega\)-consistency implies consistency).
            \item If FA \(\vdash \lnot\psi(\bar{g})\),
        Then FA \(\nvdash \psi(\bar(g))\).
        Therefore, \(\forall m, Pf(m,g,g)\) is false.
        Therefore, \(\forall m, FA \vdash \lnot\underline{Pf}(\bar{m}, \bar{g}, \bar{g})\).
        Therefore, FA \(\nvdash \exists m \underline{Pf}(m, \bar{g}, \bar{g})\).
        Therefore, FA \(\nvdash \lnot \psi(\bar{g})\).
        Contradiction.
        \end{itemize}
        Therefore, \(\psi(\bar{g})\) is undecidable.
    \end{proof}
    
    This proof can be extended to any extension \(\Sigma\) of FA
    where ``\(n\) is the GN of an axiom in \(\Sigma\)'' is recursive.
\end{theorem}
\begin{theorem}[Gödel's second incompleteness theorem]
    If FA is consistent,
    then \(FA \nvdash con\) where \(con\) encodes ``\(FA \nvdash \bar{0} = \bar{1}\)''.
    
    \begin{proof}
        Define \(Prf(x,y) \subseteq \N^2\)
        as a relation that ``\(x\) is a proof of \(y\)''
        where \(x\) is a GN of a proof and \(y\) is a GN of a sentence.
        \(Prf(x,y)\) is represented by the formula \(\underline{Prf}(x,y)\).
        Let \(n\) be the GN of the sentence ``\(\bar{0}=\bar{1}\)''.
        Let \(con\) (consistency) be \(\forall x, \lnot \underline{Prf}(x,\bar{n})\).
        Then (Gödel): FA is consistent \(\implies\) FA \(\forall con\).
        \(con \implies \psi(\bar{g})\) (from first theorem proof).
        Therefore, FA \(\vdash con \implies \psi(\bar{g})\).
        By the first incompleteness theorem, FA \(\nvdash \psi(\bar{g})\).
        If FA \(\vdash con\), FA \(\vdash \psi(\bar{g})\). Contradiction.
        Therefore, FA \(\nvdash con\).
    \end{proof}
\end{theorem}


\end{document}